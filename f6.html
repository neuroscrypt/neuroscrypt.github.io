<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8" />
  <title>Виртуальный Скелет и Лицо с Анализом</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <style>
    * { box-sizing: border-box; margin: 0; padding: 0; }
    body {
      font-family: 'Segoe UI', sans-serif;
      background: #f7f9fc;
      overflow: hidden;
    }
    /* Скрываем видео – оно используется только для анализа */
    #video { display: none; }
    /* Канвас занимает весь экран */
    #overlay {
      position: fixed;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      background: #fff;
    }


     ul#face-results {height:280px;}

    /* Панель с результатами поверх канваса */
    .panel {
      position: fixed;
      top: 20px;
      right: 20px;
      width: 300px;
      background: rgba(255,255,255,0.9);
      border-radius: 16px;
      padding: 24px;
      box-shadow: 0 10px 30px rgba(0, 0, 0, 0.1);
      z-index: 10;
    }
    .panel h2 {
      font-size: 20px;
      margin-bottom: 16px;
      border-bottom: 1px solid #eee;
      padding-bottom: 8px;
    }
    .panel ul {
      list-style: none;
      padding: 0;
      max-height: 275px;
      overflow-y: auto;
    }
    .panel li {
      padding: 8px 0;
      font-size: 16px;
      border-bottom: 1px dashed #eee;
    }
    .panel li:last-child {
      border-bottom: none;
    }
  </style>
  <!-- TensorFlow.js версии 1.7.4 для совместимости -->
  <script defer src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.7.4/dist/tf.min.js"></script>
  <!-- Face API: tinyFaceDetector, faceLandmark68Net, faceExpressionNet -->
  <script defer src="https://unpkg.com/face-api.js@0.22.2/dist/face-api.min.js"></script>
  <!-- PoseNet -->
  <script defer src="https://cdn.jsdelivr.net/npm/@tensorflow-models/posenet"></script>
</head>
<body>
  <!-- Скрытое видео для анализа -->
  <video id="video" autoplay muted playsinline></video>
  <!-- Канвас для отображения виртуальных элементов -->
  <canvas id="overlay"></canvas>
  <!-- Панель с результатами анализа -->
  <div class="panel">
    <h2>Анализ лица</h2>
    <ul id="face-results">
      <li>Загрузка...</li>
    </ul>
    <h2 style="margin-top: 24px;">Анализ позы</h2>
    <ul id="pose-results">
      <li>Загрузка...</li>
    </ul>
  </div>

  <script defer>
    window.addEventListener('load', async () => {
      const video = document.getElementById('video');
      const canvas = document.getElementById('overlay');
      const ctx = canvas.getContext('2d');
      const faceList = document.getElementById('face-results');
      const poseList = document.getElementById('pose-results');
      let posenetModel;
      // Для сглаживания лицевых точек – уменьшенный коэффициент
      let smoothedLandmarks = null;
      const smoothingFactor = 0.1;
      // Порог для поз – снижен, чтобы ключевые точки гарантированно отображались
      const minPartConfidence = 0.3;
      
      // Соединения для отрисовки скелета позы
      const poseConnections = [
        ['leftShoulder', 'rightShoulder'],
        ['leftShoulder', 'leftElbow'],
        ['leftElbow', 'leftWrist'],
        ['rightShoulder', 'rightElbow'],
        ['rightElbow', 'rightWrist'],
        ['leftShoulder', 'leftHip'],
        ['rightShoulder', 'rightHip'],
        ['leftHip', 'rightHip'],
        ['leftHip', 'leftKnee'],
        ['leftKnee', 'leftAnkle'],
        ['rightHip', 'rightKnee'],
        ['rightKnee', 'rightAnkle']
      ];

      // Устанавливаем размеры канваса равными размеру viewport
      function resizeCanvas() {
        canvas.width = window.innerWidth;
        canvas.height = window.innerHeight;
      }
      resizeCanvas();
      window.addEventListener('resize', resizeCanvas);

      // Настройка камеры: запрашиваем видео с веб-камеры с разрешением 640x480
      async function setupCamera() {
        try {
          const stream = await navigator.mediaDevices.getUserMedia({ video: { width: 640, height: 480 } });
          video.srcObject = stream;
          return new Promise(resolve => {
            video.onloadedmetadata = () => resolve(video);
          });
        } catch (error) {
          console.error("Ошибка доступа к веб-камере:", error);
        }
      }

      // Загрузка моделей face-api и posenet
      async function loadModels() {
        const MODEL_URL = 'https://justadudewhohacks.github.io/face-api.js/models';
        await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
        await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
        await faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL);
        posenetModel = await posenet.load();
      }

      // Обновление панели с результатами
      function updateList(ul, items) {
        ul.innerHTML = '';
        items.forEach(item => {
          const li = document.createElement('li');
          li.textContent = item;
          ul.appendChild(li);
        });
      }

      // Сглаживание координат лицевых точек
      function smoothLandmarks(currentLandmarks) {
        if (!smoothedLandmarks) {
          smoothedLandmarks = currentLandmarks.map(p => ({ x: p.x, y: p.y }));
        } else {
          currentLandmarks.forEach((p, i) => {
            smoothedLandmarks[i].x = smoothedLandmarks[i].x * (1 - smoothingFactor) + p.x * smoothingFactor;
            smoothedLandmarks[i].y = smoothedLandmarks[i].y * (1 - smoothingFactor) + p.y * smoothingFactor;
          });
        }
        return smoothedLandmarks;
      }

      // Отрисовка ключевых точек лица (зелёными) с учетом масштабирования
      function drawFaceLandmarks(landmarks, scaleX, scaleY) {
        const points = smoothLandmarks(landmarks.positions);
        ctx.fillStyle = 'green';
        points.forEach(p => {
          ctx.beginPath();
          ctx.arc(p.x * scaleX, p.y * scaleY, 3, 0, 2 * Math.PI);
          ctx.fill();
        });
      }

      // Отрисовка ключевых точек позы (синими) с масштабированием
      function drawPoseKeypoints(keypoints, scaleX, scaleY) {
        ctx.fillStyle = 'blue';
        keypoints.forEach(keypoint => {
          if (keypoint.score > minPartConfidence) {
            ctx.beginPath();
            ctx.arc(keypoint.position.x * scaleX, keypoint.position.y * scaleY, 5, 0, 2 * Math.PI);
            ctx.fill();
          }
        });
      }

      // Отрисовка скелета позы с масштабированием
      function drawSkeleton(keypoints, scaleX, scaleY) {
        const keypointMap = {};
        keypoints.forEach(k => { keypointMap[k.part] = k; });
        ctx.strokeStyle = 'blue';
        ctx.lineWidth = 2;
        poseConnections.forEach(([partA, partB]) => {
          const kpA = keypointMap[partA];
          const kpB = keypointMap[partB];
          if (kpA && kpB && kpA.score > minPartConfidence && kpB.score > minPartConfidence) {
            ctx.beginPath();
            ctx.moveTo(kpA.position.x * scaleX, kpA.position.y * scaleY);
            ctx.lineTo(kpB.position.x * scaleX, kpB.position.y * scaleY);
            ctx.stroke();
          }
        });
      }

      // Основной цикл анализа и отрисовки
      async function onFrame() {
        if (video.paused || video.ended) return requestAnimationFrame(onFrame);
        
        // Вычисляем масштаб между размерами видео и канваса
        const scaleX = canvas.width / video.videoWidth;
        const scaleY = canvas.height / video.videoHeight;
        
        // Заливаем фон канваса (белым)
        ctx.fillStyle = '#fff';
        ctx.fillRect(0, 0, canvas.width, canvas.height);

        // Детекция лица с landmarks и эмоциями
        const faceResults = await faceapi
          .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
          .withFaceLandmarks()
          .withFaceExpressions();

        let faceItems = [];
        if (faceResults && faceResults.length > 0) {
          faceResults.forEach(result => {
            if (result.landmarks) {
              drawFaceLandmarks(result.landmarks, scaleX, scaleY);
            }
            if (result.expressions) {
              const expressions = result.expressions;
              let exprStrings = [];
              for (const [expr, score] of Object.entries(expressions)) {
                exprStrings.push(`${expr}: ${(score * 100).toFixed(1)}%`);
              }
              faceItems.push(...exprStrings);
            }
          });
        } else {
          faceItems.push("Лицо не найдено");
        }
        updateList(faceList, faceItems);

        // Детекция позы (PoseNet) – используем flipHorizontal: true для зеркального отображения
        const pose = await posenetModel.estimateSinglePose(video, { flipHorizontal: true });
        let poseItems = [];
        if (pose && pose.keypoints) {
          drawPoseKeypoints(pose.keypoints, scaleX, scaleY);
          drawSkeleton(pose.keypoints, scaleX, scaleY);
          // Выводим информацию по первым 5 ключевым точкам
          pose.keypoints.slice(0, 5).forEach(p => {
            poseItems.push(`${p.part}: (${Math.round(p.position.x)}, ${Math.round(p.position.y)})`);
          });
        } else {
          poseItems.push("Поза не найдена");
        }
        updateList(poseList, poseItems);

        requestAnimationFrame(onFrame);
      }

      await setupCamera();
      await loadModels();
      video.play();
      onFrame();
    });
  </script>
</body>
</html>
