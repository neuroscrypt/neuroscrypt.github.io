<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Emotion and Pose Analysis</title>
  
  <!-- CDN для TensorFlow.js (PoseNet) -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/posenet"></script>

  <!-- CDN для Face API -->
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>

  <style>
    body {
      display: flex;
      justify-content: center;
      align-items: center;
      height: 100vh;
      background-color: #f0f0f0;
      margin: 0;
    }

    #canvas {
      position: absolute;
      z-index: 1;
    }

    video {
      position: absolute;
      z-index: 0;
      transform: scaleX(-1); /* Для перевернутого відображення відео */
    }
  </style>
</head>
<body>

  <video id="video" width="640" height="480" autoplay muted></video>
  <canvas id="canvas"></canvas>

  <script>
    // Завантажуємо Face API модель
    async function loadFaceApi() {
      await faceapi.nets.ssdMobilenetv1.loadFromUri('/models');
      await faceapi.nets.faceLandmark68Net.loadFromUri('/models');
      await faceapi.nets.faceExpressionNet.loadFromUri('/models');
    }

    // Ініціалізація відео потоку
    async function startVideo() {
      const video = document.getElementById('video');
      const stream = await navigator.mediaDevices.getUserMedia({
        video: true
      });
      video.srcObject = stream;
    }

    // Ініціалізація PoseNet
    let net;
    async function setupPoseNet() {
      net = await posenet.load();
    }

    // Аналіз емоцій
    async function analyzeEmotions() {
      const video = document.getElementById('video');
      const detections = await faceapi.detectAllFaces(video).withFaceLandmarks().withFaceExpressions();

      // Малюємо на canvas
      const canvas = faceapi.createCanvasFromMedia(video);
      document.body.append(canvas);
      faceapi.matchDimensions(canvas, video);
      canvas?.clear();
      faceapi.draw.drawDetections(canvas, detections);
      faceapi.draw.drawFaceExpressions(canvas, detections);
    }

    // Аналіз пози
    async function analyzePose() {
      const video = document.getElementById('video');
      const pose = await net.estimateSinglePose(video, {
        flipHorizontal: false
      });

      const canvas = document.getElementById('canvas');
      const context = canvas.getContext('2d');
      canvas.width = video.width;
      canvas.height = video.height;

      context.clearRect(0, 0, canvas.width, canvas.height);
      drawPose(pose, context);
    }

    // Малюємо позу на canvas
    function drawPose(pose, context) {
      pose.keypoints.forEach(point => {
        if (point.score > 0.5) {
          context.beginPath();
          context.arc(point.position.x, point.position.y, 5, 0, 2 * Math.PI);
          context.fillStyle = 'red';
          context.fill();
        }
      });
    }

    // Основна функція для оновлення
    async function update() {
      await analyzeEmotions();
      await analyzePose();
      requestAnimationFrame(update);
    }

    // Запуск
    async function init() {
      await loadFaceApi();
      await setupPoseNet();
      await startVideo();
      update();
    }

    init();
  </script>

</body>
</html>
